
pip install ultralytics opencv-python matplotlib
#압축 해제
import zipfile

with zipfile.ZipFile('yolo v8.v3i.yolov8.zip', 'r') as zip_ref:
    zip_ref.extractall('dataset3')
from ultralytics import YOLO

model = YOLO('yolov8n.pt')

model.train(
    data='dataset3/data.yaml',
    epochs=1000,
    imgsz=640,
    batch=8,
    workers=0,
    cache=True,
    task='detect'
)
from ultralytics import YOLO  # ✅ 이 줄이 반드시 필요해!

# 학습된 YOLOv8 객체 감지 모델 불러오기
model = YOLO('runs/train/train2/weights/best.pt')

# 원본 이미지 폴더에 대해 객체 감지 수행
results = model('dataset/train/images', save=True)  # detect는 task 생략 가능
import cv2
import os
from glob import glob

img_folder = 'runs\detect\predict2'
output_video = 'segmentation_result.mp4'

# 이미지 목록
img_files = sorted(glob(os.path.join(img_folder, '*.jpg')) + glob(os.path.join(img_folder, '*.png')))
if not img_files:
    print("❌ 결과 이미지가 없습니다.")
    exit()

# 비디오 설정
frame = cv2.imread(img_files[0])
height, width, _ = frame.shape
video = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*'mp4v'), 5, (width, height))

for img in img_files:
    video.write(cv2.imread(img))

video.release()
print(f"✅ 비디오 저장 완료: {output_video}")
from ultralytics import YOLO
import cv2

# 1. 객체 감지 모델 불러오기 (task 생략 or 명시적으로 detect)
model = YOLO('C:/Users/user/Desktop/signboard/runs/train/train2/weights/best.pt')  # detect 모델

# 2. 비디오 열기
video_path = 'C:/Users/user/Desktop/signboard/13.mp4'
cap = cv2.VideoCapture(video_path)

# 3. 출력 비디오 설정
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter('output_detect.mp4', fourcc, 30.0,
                      (int(cap.get(3)), int(cap.get(4))))

# 4. 프레임별 감지 및 저장
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    results = model(frame)
    annotated_frame = results[0].plot()

    cv2.imshow('Detection', annotated_frame)
    out.write(annotated_frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# 5. 자원 해제
cap.release()
out.release()
cv2.destroyAllWindows()
